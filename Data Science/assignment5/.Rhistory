print(d1)
d1
d2<-as.Date("1969-01-01")
unclass(d2)
Sys.time()
t1<-Sys.time()
t1
class(t1)
unclass(t1)
t2<-as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
d1
weekdays(d1)
months(d1)
months(t1)
quarters(t1)
quarters(t2)
t3
t3 <- "October 17, 1986 8:24"
t3 <- "October 17, 1986 08:24"
strptime(t3)
strptime(t3,"%B %d, %Y %H:%M")
t4<-strptime(t3,"%B %d, %Y %H:%M")
t4
class(t4)
Sys.time()>t1
Sys.time()-t1
difftime
difftime(Sys.time(),t1,units='days')
data(cars)
?cars
head()
head(cars)
plot(cars)
?plot
ccars
cars
plot(cars$speed, y=cars$dist)
plot(cars$dist,cars$speed)
skip()
plot(x=cars$speed, y=cars$dist, xlab="Speed",ylab="Stopping Distance")
plot(x=cars$speed, y=cars$dist,ylab="Stopping Distance")
plot(x=cars$speed, y=cars$dist, xlab="Speed",ylab="Stopping Distance")
skip()
skip()
plot(cars,2)
plot(cars,col=2)
plot(cars,xlim=c(10,15))
plot(cars,pch=2)
skip()
boxplot(mtcars)
?boxplot
skip()
hist(mtcars$mpg)
skip()
exit()
bye()
install.packages("RMySQL")
install.packages("RMySQL",type = "source")
library(RMySQL)
library(DBI)
library(RMySQL)
ucscDb<-dbConnect(MySQL(),user="genome",host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb,"show databases;");dbConnect(ucscDb);
View(result)
View(result)
hg19<- dbConnect(MySQL(),user="genome",db="hg19",host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListFields(hg19,"affyU133Plus2")
dbGetQuery(hg19,"select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19,"affyU133Plus2")
head(affyData)
View(affyData)
View(affyData)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affMis <- fetch(query); quantile(affMis$misMatches)
affMis
affyMisSmall <-fetch(query,n=10); dbClearResult(query);
dim(affyMisSmall)
dbDisconnect(hg19)
library(RMySQL)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created <- h5createFile("example.h5")
created
created <- h5createGroup("example.h5","foo")
created <- h5createGroup("example.h5","baa")
created <- h5createGroup("example.h5","foo/foobaa")
h51s("example.h5")
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
created<- h5createFile("example.h5")
created
created<- h5createFile("example.h5")
created
created<- h5createGroup("example.h5","foo")
created<- h5createGroup("example.h5","baa")
created<- h5createGroup("example.h5","foo/foobaa")
h51s("example.h5")
library(h51s)
install.packages("h51s")
h5ls("example.h5")
A <- matrix(1:10,nr=5,nc=2)
h5write(A,"example.h5","foo/A")
B <- array(seq(.1,2.0,by=.1),dim=c(5,2,2))
attr(B,"scale") <- "liter"
B
h5write(B,"example.h5","foo/foobaa/B")
h5ls("example.h5")
df <- data.frame(1L:5L, seq(0,1,length.out = 5),c("ab","cde","fghi","a","a"), stringsAsFactors = FALSE)
h5write(df,"example.h5","df")
h5ls("example.h5")
readA <- h5read("example.h5","foo/A")
readB <- h5read("example.h5","foo/foobaa/B")
readf <- h5read("example.h5","df")
readA
h5write(c(12,13,14),"example.h5","foo/A",index<-list(1:3,1))
h5write(c(12,13,14),"example.h5","foo/A",index=list(1:3,1))
h5read("example.h5","foo/A")
con <- url("http://scholar.google.com/citations?user=HI-16C0AAAA7&h1=en")
htmlCode <- readLines(con)
close(con)
htmlCode
library(XML)
url
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url,useInternalNodes = T)
xpathSApply(html,"//title",xmlValue)
xpathSApply(html,"//td[@id='col-citedby']",xmlValue)
xpathSApply(html,"//td[@id='col-citedby']",xmlValue)
xpathSApply(html,"//title",xmlValue)
xpathSApply(html,"//td[@id='col-citedby']",xmlValue)
library(httr)
html2<-GET(url)
content2 <- content(html2,as="text")
parsedHtml<- htmlParse(content2,asText=TRUE)
xpathSApply(parsedHtml,"//title",xmlValue)
pg1<- GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg2 <- GET('http://httpbin.org/basic-auth/user/passwd')
pg2 <- GET('http://httpbin.org/basic-auth/user/passwd',authenticate("user","passwd"))
pg2
google <- handle("http://google.com")
pg1 <- GET(handle <- google,path="/")
google <- handle("http://google.com")
pg1 <- GET(handle = google,path="/")
pg2 <- GET(handle = google,path="search")
pg1
pg2
myapp <- oauth_app("twitter",key="yourConsumerKeyHere",secret = "yourConsumerSecretHere")
sig <- sign_oauth1.0(myapp,token <- "yourTokenHere",token_secret = "yourTokenSecretHere")
homeTL<- GET("https://api.twitter.com/1.1/statuses/home_timeline.json",sig)
con <- url("http://scholar.google.com/citations?user=HI-16C0AAAAJ&h1=en")
htmlCode <- readLines(con)
htmlCode
close(con)
htmlCode
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = 1)
xpathApply(html,"//title",xmlValue)
xpathApply(html,"//td[@id='col-citedby']",xmlValue)
xpathApply(html,"//td",xmlValue)
library(httr)
url
library(httr); html2 = GET(url)
content2<- content(html2,as="text")
parsedHtml <- htmlParse(content2, asText = TRUE)
xpathSApply(parsedHtml,"//title",xmlValue)
pg1<- GET("http://httpbin.org/basic-auth/user/passwd")
pg1
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",)
myapp <- oauth_app("github",key ="a7e6963fad193aae48d7", secret = "7d849fbe7b68f0e4fceb9b3b6998a9ddd8a039c3")
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
myapp <- oauth_app("github",key ="a7e6963fad193aae48d7", secret = "7d849fbe7b68f0e4fceb9b3b6998a9ddd8a039c3")
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",key = "a7e6963fad193aae48d7", secret = "7d849fbe7b68f0e4fceb9b3b6998a9ddd8a039c3")
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit",gtoken)
stop_for_status(req)
content(req)
myapp <- oauth_app("twitter",key="RqR6ablottRaN2csMjxWOLPMP",secret <- "TNCA16VKNhscGKWdKSLlaJ1DsprKoj8ybVwqrSOML7rvZEQ5v")
oauth_app
library(oauth_app)
install.packages("oauth_app")
library(httr)
myapp <- oauth_app("twitter",key="RqR6ablottRaN2csMjxWOLPMP", secret = "iTNCA16VKNhscGKWdKSLlaJ1DsprKoj8ybVwqrSOML7rvZEQ5v")
sig <- sign_oauth1.0(myapp,token = "3423649217-1LIofOLYFfqoGuPZDMt6hzGh6tUUKYZNMbNXXxw", token_secret = "ZeBdhdHsHuhTZilNmwZDxUlNEUuCHFlXNTw4D1422xnmT")
homeTL <- GET("https://api.twitter.com/1.1/statuses/home_timeline.json",sig)
homeTL <- GET("https://api.twitter.com/1.1/statuses/home_timeline.json",sig)
library(jsonlite)
json1<- content(homeTL)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",key = "a7e6963fad193aae48d7", secret = "7d849fbe7b68f0e4fceb9b3b6998a9ddd8a039c3")
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
library(httpuv)
install.packages("httpuv")
myapp <- oauth_app("github",key = "a7e6963fad193aae48d7", secret = "7d849fbe7b68f0e4fceb9b3b6998a9ddd8a039c3")
github_token<- oauth2.0_token(oauth_endpoints("github"),myapp)
myapp <- oauth_app("github",key = "a7e6963fad193aae48d7", secret = "7d849fbe7b68f0e4fceb9b3b6998a9ddd8a039c3")
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
myapp <- oauth_app("github",key = "a7e6963fad193aae48d7", secret = "7d849fbe7b68f0e4fceb9b3b6998a9ddd8a039c3")
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
gtoken <- oauth2.0_token(oauth_endpoints("github"),myapp)
req <- GET("https://api.github.com/rate_limit)",gtoken)
stop_for_status(req)
stop_for_status(req)
content(req)
oauth_endpoints("github")
myapp <- oauth_app("github",key = "a7e6963fad193aae48d7", secret = "7d849fbe7b68f0e4fceb9b3b6998a9ddd8a039c3")
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
gtoken <- config(ttoken = github_token)
req <- GET("https://api.github.com/rate_limit",gtoken)
req <- GET("https://api.github.com/rate_limit",gtoken)
req <- GET("https://api.github.com/rate_limit",gtoken)
stop_for_status(req)
content(req)
library(reshape2)
head(mtcars)
data<-mtcars
data$carname<-rownames(data)
View(data)
View(data)
dim(mtcars)
data_melt=melt(data,id=c("carname","cyl","gear"),measure.vars = c("hp","mpg"))
View(data_melt)
View(data_melt)
cylData<-dcast(data_melt,cyl-variable)
dcast(data_melt,cyl-variable)
dcast(data_melt,cyl~variable)
dcast(data_melt,cyl~variable,sum)
dcast(data_melt,cyl~variable,mean)
load(url("http://www.openintro.org/stat/data/ames.RData"))
population <-ames$Gr.Liv.Area
samp <- sample(population,60)
barplot(samp)
hist(samp)
hist(population)
sample_mean <- mean(samp)
summary(sample_mean)
summary(samp)
se <- sd(samp)/sqrt(60)
lower <- sample_mean - 1.96 * se
upper <- sample_mean + 1.96 * se
c(lower, upper)
mean(population)
samp_mean <- rep(NA, 50)
samp_sd <- rep(NA, 50)
n <- 60
for(i in 1:50){
samp <- sample(population, n) # obtain a sample of size n = 60 from the population
samp_mean[i] <- mean(samp)    # save sample mean in ith element of samp_mean
samp_sd[i] <- sd(samp)        # save sample sd in ith element of samp_sd
}
lower <- samp_mean - 1.96 * samp_sd / sqrt(n)
upper <- samp_mean + 1.96 * samp_sd / sqrt(n)
c(lower[1],upper[1])
plot_ci(lower, upper, mean(population))
pnorm(.975)
qnorm(.975)
qnorm(.99)
qnorm(.995)
?pt
pt(2,50,lower.tail = FALSE)
pt(2,50,lower.tail = FALSE)*2
pt(2,10,lower.tail = FALSE)*2
qt(.25,df=21)
qt(.025,df=21)
pt(2.3,df=21)
pt(2.3,df=21,lower.tail = FALSE)
pt(2.3,df=21,lower.tail = FALSE)*2
qt(.025,df=21)
qt(.975,df=21)
pt(2.21,df=21,lower.tail = FALSE)*2
pt(-.87,df=199,lower.tail = FALSE)*2
pt(-.87,df=199)
?pnorm
pnorm(-.2)
rnorm(.8)
qnorm(.42)
qnorm(.80)
qt(.025,25)
qt(.975,25)
library("caret")
library("ggplot2")
library("lattice")
install.packages("pbkrtest")
qplot(chl_small, pe, colour = pop, data = data)
```{r}
data<-read.csv("seaflow_21min.csv")
#splitting to train and test data
smp_size <- floor(0.5 * nrow(data))
## set the seed to make your partition reproductible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
```
Mean of training set variable time
```{r}
mean(train$time)
```
Plotting pe against chl_small and color by pop
```{r}
qplot(chl_small, pe, colour = pop, data = data)
library(ggplot2)
qplot(chl_small, pe, colour = pop, data = data)
library(lattice)
qplot(chl_small, pe, colour = pop, data = data)
data<-read.csv("seaflow_21min.csv")
#splitting to train and test data
getwd()
setwd("c:/users/atx/box sync")
setwd("c:/users/atx/box sync/box sync")
dir()
setwd("c:/users/atx/box sync/box sync/datasci_course_materials_master")
setwd("c:/users/atx/box sync/box sync/datasci_course_materials_master")
setwd("c:/users/atx/box sync/box sync/datasci_course_materials-master")
setwd("c:/users/atx/box sync/box sync/datasci_course_materials-master/assignment5")
dir()
library(ggplot2)
library(lattice)
data<-read.csv("seaflow_21min.csv")
#splitting to train and test data
smp_size <- floor(0.5 * nrow(data))
## set the seed to make your partition reproductible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
mean(train$time)
qplot(chl_small, pe, colour = pop, data = data)
library("rpart")
fol <- formula(pop ~ fsc_small + fsc_perp + fsc_big + pe + chl_small + chl_big)
model <- rpart(fol,method = "class", data = train)
print(model)
library(randomForest)
model_rForest <- randomForest(fol,method = "class", data = train)
print(model_rForest)
prediction_rForest<-predict(model_rForest,test,type = "class")
totalMatch_rForest=sum(test$pop==prediction_rForest)
accuracy_rForest=totalMatch_rForest/length(test$pop)
accuracy_rForest
importance(model_rForest)
print(model)
library("e1071")
model_svm=svm(fol,data = train,method="class")
prediction_svm<-predict(model_svm,test,type = "class")
totalMatch_svm=sum(test$pop==prediction_svm)
accuracy_svm=totalMatch_svm/length(test$pop)
accuracy_svm
table(pred = prediction, true = test$pop)
prediction<-predict(model1,test,type = "class")
prediction<-predict(model,test,type = "class")
table(pred = prediction, true = test$pop)
table(pred = prediction_rForest, true = test$pop)
table(pred = prediction_svm, true = test$pop)
newtrain<-train[which(train$file_id!=208),]
newtest<-test[which(test$file_id!=208),]
model_svm_new=svm(fol,data = newtrain,method="class")
prediction_svm_new<-predict(model_svm_new,newtest,type = "class")
totalMatch_svm_new=sum(newtest$pop==prediction_svm_new)
accuracy_svm=totalMatch_svm_new/length(newtest$pop)
accuracy_svm
accuracy_svm
totalMatch_svm=sum(test$pop==prediction_svm)
accuracy_svm=totalMatch_svm/length(test$pop)
accuracy_svm
summary(data)
mean(train$time)
print(model)
accuracy
totalMatch=sum(test$pop==prediction)
accuracy=totalMatch/length(test$pop)
accuracy
accuracy_rForest
importance(model_rForest)
accuracy_svm
table(pred = prediction, true = test$pop)
table(pred = prediction_rForest, true = test$pop)
table(pred = prediction_svm, true = test$pop)
totalMatch_svm_new=sum(newtest$pop==prediction_svm_new)
accuracy_svm_new=totalMatch_svm_new/length(newtest$pop)
accuracy_svm_new
accuracy_svm_new-accuracy_svm
install.packages("entropy")
library(entropy)
?mi.empirical
mi.empirical(train$fsc_big,train$pop)
mi.empirical(train$fsc_big,train$pop, unit = c("log2"))
train$pop
mi.empirical(train$fsc_big,train$pop, unit = c("log2"))
mi.empirical(train$fsc_big,train$pop, unit = c("log2"))
y = c(4, 2, 3, 0, 2, 4, 0, 0, 2, 1, 1)
y
y = rbind( c(1,2,3), c(6,5,4) )
y
mi.empirical(y)
test_x=train$fsc_big[1:10,]
test_x=train$fsc_big[1:10,:]
test_x=train[1:10,:]
test_x=train[1:10]
test_x=train[:,1:10]
test_x=train[1:10]
test_x=train[1:10,]
y=rbind(test_x$fsc_big,test_x$pop)
y
mi.empirical(y)
dir()
data<-read.csv('titanic_train.csv')
rm all
?rm
rm(list=ls(all=TRUE))
data<-read.csv('titanic_train.csv')
summary(data)
smp_size <- floor(0.7 * nrow(data))
## set the seed to make your partition reproductible
set.seed(123)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
mi.empirical(rbind(train$PClass.1,train$Survived))
train$Survived
train$PClass.1
ribind(train$PClass.1,train$Survived)
rbind(train$PClass.1,train$Survived)
y<-rbind(train$PClass.1,train$Survived)
mi.empirical(y)
y<-rbind(train$PClass.1[1:10],train$Survived[1:10])
mi.empirical(y)
test_x=train[1:10,]
rbind(test_x$PClass.1,test_x$Survived)
y<-rbind(test_x$PClass.1,test_x$Survived)
mi.empirical(y)
y=rbind(test_x$PClass.1,test_x$Survived)
mi.empirical(y)
data<-read.csv("seaflow_21min.csv")
test_x=data[1:10,]
y=rbind(test_x$fsc_big,test_x$pop)
mi.empirical(y)
y<-rbind(train$PClass.1[1:10],train$Survived[1:10])
mi.empirical(y)
data<-read.csv('titanic_train.csv')
summary(data)
train$age.31)
library(rpart)
fol <- formula(Survived ~ PClass.1 + PClass.2 + PClass.3 + X7.91.fare.14.45 +
X14.45.fare.31 + fare.31+Sibsp..2+Sibsp.2+X11.age.20+X20.age.31+
train$age.31)
model <- rpart(fol,method = "class", data = train)
print(model)
prediction<-predict(model,test)
data<-read.csv('titanic_train.csv')
summary(data)
```
smp_size <- floor(0.7 * nrow(data))
```{r}
set.seed(123)
## set the seed to make your partition reproductible
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind, ]
test <- data[-train_ind, ]
```
```{r}
library(rpart)
fol <- formula(Survived ~ PClass.1 + PClass.2 + PClass.3 + X7.91.fare.14.45 +
X14.45.fare.31 + fare.31+Sibsp..2+Sibsp.2+X11.age.20+X20.age.31+
train$age.31)
model <- rpart(fol,method = "class", data = train)
print(model)
prediction<-predict(model,test)
prediction<-predict(model,test)
totalMatch=sum(test$Survived==prediction)
prediction<-predict(model,test)
model <- rpart(fol,method = "class", data = train)
print(model)
prediction<-predict(model,test)
test
prediction<-predict(model,test)
length(test$PassengerId)
length(test$age.31)
prediction<-predict(model,test,type = "class")
print(model)
prediction<-predict(model,test,type = "class")
prediction<-predict(model,test,type = "class")
totalMatch=sum(test$Survived==prediction)
prediction<-predict(model,train,type = "class")
totalMatch=sum(train$Survived==prediction)
accuracy=totalMatch/length(train$Survived)
accuracy
prediction<-predict(model,train,type = "class")
totalMatch=sum(train$Survived==prediction)
accuracy=totalMatch/length(train$Survived)
prediction<-predict(model,test,type = "class")
model <- rpart(fol, data = train)
print(model)
prediction<-predict(model,test,type = "class")
